input {
  beats { 
    port => 9400
  }
}

filter {
  if [message] =~ /"type":"throughput"/ {
    # Sanitise diags, preserving any trailing comma
    mutate {
        gsub => [
            "message",
            '(?m)"diags"\s*:\s*"(?:\\.|[^"\\])*?"\s*,', '"diags":"[removed_for_parsing]",',
            "message",
            '(?m)"diags"\s*:\s*"(?:\\.|[^"\\])*?"',      '"diags":"[removed_for_parsing]"'
        ]
    }
  }
}

# IMPORTANT: Process connectivity tests FIRST before general pssid processing
filter {
    # Parse connectivity tests (pssid-dhcp and pssid-80211)
    if [message] =~ /pssid: pssid-(dhcp|80211)/ {
        
        # Clone the original message before any modifications
        mutate {
            add_field => { "[@metadata][original_message]" => "%{message}" }
        }
        
        # Extract the test type and JSON payload with better pattern matching
        grok {
            match => { 
                "message" => "pssid: pssid-(?<connectivity_test_type>dhcp|80211)(?:\s+\w+)?\s+\([^)]+\):\s+(?<connectivity_json>\{.+\}$)" 
            }
            tag_on_failure => ["_grokparsefailure_connectivity"]
        }
        
        # Parse the JSON if grok succeeded
        if "_grokparsefailure_connectivity" not in [tags] {
            json {
                source => "connectivity_json"
                target => "connectivity_data"
                tag_on_failure => ["_jsonparsefailure_connectivity"]
            }
            
            # Only proceed if JSON parsing succeeded
            if "_jsonparsefailure_connectivity" not in [tags] {
                
                # Extract basic test info
                mutate {
                    add_field => {
                        "[connectivity][test_type]" => "%{connectivity_test_type}"
                        "[connectivity][status_code]" => "%{[connectivity_data][status_code]}"
                        "[connectivity][status_msg]" => "%{[connectivity_data][status_msg]}"
                    }
                }
                
                # Determine success/failure
                if [connectivity_data][status_code] == 0 {
                    mutate {
                        add_field => { "[connectivity][result]" => "success" }
                    }
                } else {
                    mutate {
                        add_field => { "[connectivity][result]" => "failure" }
                    }
                }
                
                # Process DHCP tests (Layer 3)
                if [connectivity_test_type] == "dhcp" {
                    # Extract SSID from the beginning of the message
                    grok {
                        match => {
                            "[@metadata][original_message]" => "pssid: pssid-dhcp(?:\s+\w+)?\s+\(SSID:\s+(?<temp_ssid>[^\)]+)\)"
                        }
                        tag_on_failure => ["_grokparsefailure_dhcp_ssid"]
                    }
                    
                    # Set the SSID fields if extraction succeeded
                    if "_grokparsefailure_dhcp_ssid" not in [tags] and [temp_ssid] {
                        mutate {
                            add_field => { "[connectivity][wifi_ssid]" => "%{temp_ssid}" }
                        }
                        
                        # Create index-safe SSID (lowercase, replace special chars)
                        mutate {
                            copy => { "[connectivity][wifi_ssid]" => "[connectivity][wifi_ssid_safe]" }
                        }
                        
                        mutate {
                            lowercase => ["[connectivity][wifi_ssid_safe]"]
                            # gsub => ["[connectivity][wifi_ssid_safe]", "[^a-z0-9]+", "_"]
                        }
                        
                        mutate {
                            remove_field => ["temp_ssid"]
                        }
                    }
                    
                    ruby {
                        code => '
                            dhcpcd_log = event.get("[connectivity_data][dhcpcd_log]") || []
                            
                            if dhcpcd_log.any?
                                # Find key events
                                start_time = nil
                                lease_time = nil
                                
                                dhcpcd_log.each do |entry|
                                    msg = entry["msg"] || ""
                                    time = entry["time"]
                                    
                                    # Track DHCP solicitation start
                                    if msg.include?("soliciting a DHCP lease") && start_time.nil?
                                        start_time = time
                                    end
                                    
                                    # Track successful lease
                                    if msg.match(/leased .* for \d+ seconds/)
                                        lease_time = time
                                    end
                                end
                                
                                # Calculate duration if we have both times
                                if start_time && lease_time
                                    duration = lease_time - start_time
                                    event.set("[connectivity][dhcp_lease_duration_seconds]", duration)
                                end
                                
                                # Extract IP address if leased
                                lease_entry = dhcpcd_log.find { |e| e["msg"] && e["msg"].match(/leased (.+) for/) }
                                if lease_entry
                                    ip_match = lease_entry["msg"].match(/leased (.+) for/)
                                    event.set("[connectivity][assigned_ip]", ip_match[1]) if ip_match
                                end
                                
                                # Count total DHCP events
                                event.set("[connectivity][dhcp_event_count]", dhcpcd_log.length)
                            end
                        '
                    }
                }
                
                # Process 802.11 tests (Layer 2)
                if [connectivity_test_type] == "80211" {
                    ruby {
                        code => '
                            wpa_log = event.get("[connectivity_data][wpa_log]") || []
                            
                            if wpa_log.any?
                                # Find key WiFi events
                                associate_start_time = nil
                                connected_time = nil
                                ssid = nil
                                bssid = nil
                                
                                wpa_log.each do |entry|
                                    msg = entry["msg"] || ""
                                    time = entry["time"]
                                    
                                    # Track association attempt and extract SSID
                                    if msg.include?("Trying to associate with SSID") && associate_start_time.nil?
                                        associate_start_time = time
                                        # Extract SSID from message
                                        ssid_match = msg.match(/SSID \'([^\']+)\'/)
                                        ssid = ssid_match[1] if ssid_match
                                    end
                                    
                                    # Track successful connection
                                    if msg.include?("CTRL-EVENT-CONNECTED")
                                        connected_time = time
                                        bssid_match = msg.match(/Connection to ([a-fA-F0-9:]+)/)
                                        bssid = bssid_match[1] if bssid_match
                                    end
                                end
                                
                                # Calculate association duration
                                if associate_start_time && connected_time
                                    duration = connected_time - associate_start_time
                                    event.set("[connectivity][wifi_association_duration_seconds]", duration)
                                end
                                
                                # Set WiFi details
                                event.set("[connectivity][wifi_ssid]", ssid) if ssid
                                event.set("[connectivity][wifi_bssid]", bssid) if bssid
                                
                                # Create index-safe SSID (lowercase, replace special chars)
                                if ssid
                                    safe_ssid = ssid.downcase.gsub(/[^a-z0-9]+/, "_")
                                    event.set("[connectivity][wifi_ssid_safe]", safe_ssid)
                                end
                                
                                # Check for authentication details
                                eap_success = wpa_log.any? { |e| e["msg"] && e["msg"].include?("EAP authentication completed successfully") }
                                event.set("[connectivity][eap_auth_success]", eap_success)
                                
                                # Count total WiFi events
                                event.set("[connectivity][wifi_event_count]", wpa_log.length)
                                
                                # Check for disconnection
                                disconnected = wpa_log.any? { |e| e["msg"] && e["msg"].include?("CTRL-EVENT-DISCONNECTED") }
                                event.set("[connectivity][disconnected]", disconnected)
                            end
                        '
                    }
                }
                
                # Clean up temporary fields
                mutate {
                    remove_field => ["connectivity_data", "connectivity_json", "connectivity_test_type"]
                }
                
                # Add tags for easier filtering
                mutate {
                    add_tag => ["connectivity_test", "pssid_%{[connectivity][test_type]}"]
                }
                
                # Skip further processing for connectivity tests
                mutate {
                    add_tag => ["skip_pscheduler_processing"]
                }
            }
        }
    }
}


# from https://github.com/perfsonar/logstash/blob/master/perfsonar-logstash/perfsonar-logstash/pipeline/02-pscheduler_common.conf
# Do some common tasks common to all tasks:
#   1. Remove the schedule object so we can replace with [task][schedule]
#   2. Build the pscheduler object
#   3. Remove run, task and tool
#   4. Generate a checksum used to identify same test with ruby script
#           NOTE: fingerprint filter can't handle nested objects

filter {
    # Skip processing for connectivity tests
    if "skip_pscheduler_processing" not in [tags] {
        if [message] {
            # First, check if this is a pssid message and parse accordingly
            if [message] =~ "^.*pssid:\\s*\\{" {
                # Extract just the JSON part from pssid messages
                grok {
                    match => { "message" => "pssid:\s*(?<json_message>\{.+\}$)" }
                    tag_on_failure => ["_grokparsefailure_pssid"]
                }
                
                if "_grokparsefailure_pssid" not in [tags] {
                    mutate {
                        replace => { "message" => "%{json_message}" }
                        remove_field => ["json_message"]
                    }
                    
                    # Parse the JSON
                    json {
                        source => "message"
                        tag_on_failure => ["_jsonparsefailure_pscheduler"]
                    }
                }
            } else {
                # For non-pssid messages, try the old format
                grok {
                    match => { "message" => "pssid: %{GREEDYDATA:json_message}" }
                }

                mutate {
                    replace => { "message" => "%{json_message}" }
                    remove_field => ["json_message"]
                }
            }

            # Only run Ruby script if we don't already have parsed JSON
            if "_jsonparsefailure_pscheduler" not in [tags] and ![test] {
                ruby {
                    path => "/usr/share/logstash/pipeline/ruby/pscheduler_proxy_normalize.rb"
                }
                if [pscheduler_event] {
                    ruby {
                        code => '
                            event.get("pscheduler_event").each { |k, v| event.set(k, v) }
                        '
                    }
                    mutate {
                        remove_field => ["pscheduler_event"]
                    }
                }
            }

        }

        mutate {
            remove_field => [ "schedule" ]
        }
        
        mutate {
            rename => {
                "[task][schedule]" => "[schedule]"
                "[run][added]" => "[pscheduler][added]"
                "[run][start-time]" => "[pscheduler][start_time]"
                "[run][end-time]" => "[pscheduler][end_time]"
                "[participants]" => "[pscheduler][participants]"
                "[tool][name]" => "[pscheduler][tool]"
                "[task][detail][duration]" => "[pscheduler][duration]"
                "[task][href]" => "[pscheduler][task_href]"
                "[run][href]" => "[pscheduler][run_href]"
            }
            remove_field => ["run", "task", "tool"]
        }
        
        if [pscheduler][task_href] and [pscheduler][run_href] {
          dissect {
              mapping => {
                  "[pscheduler][task_href]" => "%{?url}/tasks/%{[pscheduler][task_id]}"
                  "[pscheduler][run_href]" => "%{?url}/runs/%{[pscheduler][run_id]}"
              }
          }
        }

        #if using HTTP connector, have the option to use custom header that gives better hint of observer
        mutate {
            rename => {
                "[headers][x_ps_observer]" => "[@metadata][ps_observer]"
            }
        }
        #remove HTTP header fields if present
        mutate {
            remove_field => ["headers"]
        }
        
        ruby {
            path => "/usr/share/logstash/pipeline/ruby/pscheduler_test_checksum.rb"
        }
    }
}

# Make source, dest and ip_version consistent
filter {
    if "skip_pscheduler_processing" not in [tags] {
        ruby {
            path => "/usr/share/logstash/pipeline/ruby/pscheduler_normalize_endpoints.rb"
        }
    }
}

# Convert IS8601 durations in common fields to seconds
filter {
    if "skip_pscheduler_processing" not in [tags] {
        ruby {
            path => "/usr/share/logstash/pipeline/ruby/pscheduler_iso8601_duration.rb"
            script_params => { 
                "fields" => [
                    "[pscheduler][duration]",
                    "[schedule][slip]",
                    "[schedule][repeat]"
                ]
            }
        }
    }
}

# Lookup GeoIP information for IP fields
filter {
    if "skip_pscheduler_processing" not in [tags] {
        if [meta][source][ip] {
            geoip {
                default_database_type => "City"
                source => "[meta][source][ip]"
                target => "[meta][source][geo]"
                fields => [ "location", "city_name", "country_name", "continent_name" ]
            }
            geoip {
              default_database_type => "ASN"
              fields => [ "autonomous_system_number", "autonomous_system_organization" ]
              source => "[meta][source][ip]"
              target => "[meta][source][geo][as]"
            }
            mutate {
              rename => {
                "[meta][source][geo][as][asn]"    => "[meta][source][geo][as][number]"
                "[meta][source][geo][as][as_org]" => "[meta][source][as][organization]"
              }
            }
        }
        
        if [meta][destination][ip] {
            geoip {
                default_database_type => "City"
                source => "[meta][destination][ip]"
                target => "[meta][destination][geo]"
                fields => [ "location", "city_name", "country_name", "continent_name" ]
            }
            geoip {
              default_database_type => "ASN"
              fields => [ "autonomous_system_number", "autonomous_system_organization" ]
              source => "[meta][destination][ip]"
              target => "[meta][destination][geo][as]"
            }
            mutate {
              rename => {
                "[meta][destination][geo][as][asn]"    => "[meta][destination][geo][as][number]"
                "[meta][destination][geo][as][as_org]" => "[meta][destination][as][organization]"
              }
            }
        }
        
        if [meta][observer][ip] {
            geoip {
                default_database_type => "City"
                source => "[meta][observer][ip]"
                target => "[meta][observer][geo]"
                fields => [ "location", "city_name", "country_name", "continent_name" ]
            }
            geoip {
              default_database_type => "ASN"
              fields => [ "autonomous_system_number", "autonomous_system_organization" ]
              source => "[meta][observer][ip]"
              target => "[meta][observer][geo][as]"
            }
            mutate {
              rename => {
                "[meta][observer][geo][as][asn]"    => "[meta][observer][geo][as][number]"
                "[meta][observer][geo][as][as_org]" => "[meta][observer][as][organization]"
              }
            }
        }
    }
}


# HTTP TEST
filter {
    if [test][type] == "http" and "skip_pscheduler_processing" not in [tags] {
        ruby {
            path => "/usr/share/logstash/pipeline/ruby/pscheduler_iso8601_duration.rb"
            script_params => { 
                "fields" => [
                    "[result][time]"
                ]
            }
        }
        mutate {
            lowercase => ["[reference][SSID]"]
        }
    }
}

###########################################################################
# 30-pscheduler_throughput.conf
# Sanitises and parses pscheduler “throughput” events
###########################################################################

filter {
  if [test][type] == "throughput" {

    # ruby {
    #   path => "/usr/share/logstash/pipeline/ruby/pscheduler_iso8601_duration.rb"
    #   script_params => { "fields" => ["[pscheduler][duration]"] }
    # }

    mutate {
      rename => {
        "[result][succeeded]"                                => "[@metadata][result][succeeded]"
        "[result][summary][summary][throughput-bits]"        => "[@metadata][result][throughput]"
        "[result][summary][streams][rtt]"                    => "[@metadata][result][rtt]"
        "[result][summary][streams]"                         => "[@metadata][result][streams][json]"
        "[result][summary][summary][retransmits]"            => "[@metadata][result][retransmits]"
      }
    }

    ## ***DROP*** the huge per-second array
    mutate { remove_field => ["[result][intervals]"] }

    ## throw away the now-empty result container
    mutate { remove_field => ["result"] }

    ## bring the good stuff back into the event body
    mutate { rename => { "[@metadata][result]" => "result" } }

    mutate { lowercase => ["[reference][SSID]"] }
  }
}


filter {
    if [test][type] == "latency" or [test][type] == "latencybg" and "skip_pscheduler_processing" not in [tags] {
        mutate {
            rename => {
                "[result][succeeded]" => "[@metadata][result][succeeded]"
                "[result][error]" => "[@metadata][result][error]"
                "[result][max-clock-error]" => "[@metadata][result][max_clock_error]"
                "[result][packets-duplicated]" => "[@metadata][result][packets][duplicated]"
                "[result][packets-lost]" => "[@metadata][result][packets][lost]"
                "[result][packets-received]" => "[@metadata][result][packets][received]"
                "[result][packets-reordered]" => "[@metadata][result][packets][reordered]"
                "[result][packets-sent]" => "[@metadata][result][packets][sent]"
            }
        }
        
        #calculate packet loss
        ruby {
            code => "
                sent = event.get('[@metadata][result][packets][sent]')
                lost = event.get('[@metadata][result][packets][lost]')
                if lost and sent and sent > 0 then
                    event.set('[@metadata][result][packets][loss]', lost.to_f/sent.to_f)
                end
            "
        }

        ruby {
            path => "/usr/share/logstash/pipeline/ruby/pscheduler_histogram.rb"
            script_params => {
                "source" => "[result][histogram-latency]"
                "target" => "[@metadata][result][latency]"
                #you can also configure quantiles
            }
        }
        
        ruby {
            path => "/usr/share/logstash/pipeline/ruby/pscheduler_histogram.rb"
            script_params => {
                "source" => "[result][histogram-ttl]"
                "target" => "[@metadata][result][ttl]"
            }
        }
        
        mutate {
            remove_field => ["result"]
        }

        mutate {
            lowercase => ["[reference][SSID]"]
        }
        
        mutate {
            rename => { 
                "[@metadata][result]" => "result"
            }
        }
    }
}

filter {
    if [test][type] == "rtt" and "skip_pscheduler_processing" not in [tags] {
        
        ruby {
            path => "/usr/share/logstash/pipeline/ruby/pscheduler_iso8601_duration.rb"
            script_params => { 
                "fields" => [
                    "[test][spec][interval]",
                    "[test][spec][timeout]",
                    "[test][spec][deadline]",
                    "[result][min]",
                    "[result][max]",
                    "[result][mean]",
                    "[result][stddev]"
                ]
            }
        }
        
        mutate {
            rename => {
                "[result][succeeded]" => "[@metadata][result][succeeded]"
                "[result][error]" => "[@metadata][result][error]"
                "[result][duplicates]" => "[@metadata][result][packets][duplicated]"
                "[result][lost]" => "[@metadata][result][packets][lost]"
                "[result][loss]" => "[@metadata][result][packets][loss]"
                "[result][received]" => "[@metadata][result][packets][received]"
                "[result][reorders]" => "[@metadata][result][packets][reordered]"
                "[result][sent]" => "[@metadata][result][packets][sent]"
                "[result][roundtrips]" => "[@metadata][result][packets][json]"
                "[result][min]" => "[@metadata][result][rtt][min]"
                "[result][max]" => "[@metadata][result][rtt][max]"
                "[result][mean]" => "[@metadata][result][rtt][mean]"
                "[result][stddev]" => "[@metadata][result][rtt][stddev]"
            }
        }
        
        mutate {
            remove_field => ["result"]
        }

        mutate {
            lowercase => ["[reference][SSID]"]
        }

        mutate {
            rename => { 
                "[@metadata][result]" => "result"
            }
        }
    }
}

# https://github.com/perfsonar/logstash/blob/master/perfsonar-logstash/perfsonar-logstash/pipeline/99-outputs.conf
output {
    
    if [test][type] and [agent][name] and [reference][SSID] {
        opensearch {
            hosts => ["${OPENSEARCH_HOST}"]
            ssl_certificate_verification => false
            user => "${OPENSEARCH_USER}"
            password => "${OPENSEARCH_PASSWORD}"
            action => "create"
            index => "pscheduler_%{[test][type]}_%{[agent][name]}_%{[reference][SSID]}"
        }
    } else if [test][type] {
        # Fallback for tests missing agent name or SSID
        stdout {
            codec => line {
                format => "MISSING FIELDS: test_type=%{[test][type]} agent=%{[agent][name]} ssid=%{[reference][SSID]}"
            }
        }
    }
    
    # Handle 802.11 tests with SSID
    if [connectivity][test_type] == "80211" {
        opensearch {
            hosts => ["${OPENSEARCH_HOST}"]
            ssl_certificate_verification => false
            user => "${OPENSEARCH_USER}"
            password => "${OPENSEARCH_PASSWORD}"
            action => "create"
            # Use the index-safe SSID
            index => "pscheduler_80211_%{[agent][name]}_%{[connectivity][wifi_ssid_safe]}"
        }
    }
    
    if [connectivity][test_type] == "dhcp" {
        opensearch {
            hosts => ["${OPENSEARCH_HOST}"]
            ssl_certificate_verification => false
            user => "${OPENSEARCH_USER}"
            password => "${OPENSEARCH_PASSWORD}"
            action => "create"
            # Use SSID in index name if available, otherwise just dhcp
            index => "pscheduler_dhcp_%{[agent][name]}_%{[connectivity][wifi_ssid_safe]}"
        }
    }
}

output {
  stdout {
    codec => rubydebug
  }
}